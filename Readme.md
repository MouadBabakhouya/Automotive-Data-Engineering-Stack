# üöó Moroccan Automotive Market ‚Äî Real-Time Data Engineering Pipeline

A comprehensive **End-to-End Data Pipeline** designed to scrape, process, and visualize real-time data from the Moroccan automotive market. The system provides actionable insights into vehicle pricing trends, brand popularity, and market fluctuations across Moroccan cities.

---

## üìå Table of Contents

- [Overview](#overview)
- [Tech Stack](#tech-stack)
- [System Architecture](#system-architecture)
- [Project Structure](#project-structure)
- [Getting Started](#getting-started)
- [Key Features](#key-features)
- [Sample Insights](#sample-insights)
- [Roadmap](#roadmap)

---

## Overview

This project automates the collection of automotive listing data from Moroccan classifieds, streams it through a distributed messaging system, processes it with Apache Spark, and stores it across multiple storage layers ‚Äî enabling both real-time dashboards and batch analytics.

---

## üõ†Ô∏è Tech Stack

| Layer | Technology |
|---|---|
| **Scraping** | Python, Selenium, BeautifulSoup |
| **Orchestration** | Apache Airflow |
| **Streaming** | Apache Kafka |
| **Processing** | Apache Spark (Streaming & Batch) |
| **Data Lake** | Hadoop HDFS |
| **NoSQL Storage** | Apache Cassandra, MongoDB |
| **SQL Storage** | MySQL |
| **Visualization** | Tableau, Power BI |
| **Infrastructure** | Docker, Linux / Bash |

---

## üèóÔ∏è System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. EXTRACTION                                               ‚îÇ
‚îÇ     Selenium + BeautifulSoup ‚Üí Moroccan auto classifieds     ‚îÇ
‚îÇ     Scheduled by Apache Airflow DAGs                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2. INGESTION                                                ‚îÇ
‚îÇ     Kafka Producer ‚Üí Kafka Topics ‚Üí Kafka Consumer           ‚îÇ
‚îÇ     Decoupled, fault-tolerant streaming layer                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  3. PROCESSING                                               ‚îÇ
‚îÇ     Spark Streaming ‚Üí real-time cleaning & transformation    ‚îÇ
‚îÇ     Spark Batch    ‚Üí historical aggregations & analytics     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ                          ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  4. RAW STORAGE       ‚îÇ    ‚îÇ  5. PROCESSED STORAGE           ‚îÇ
‚îÇ     Hadoop HDFS       ‚îÇ    ‚îÇ     Cassandra (high-velocity)   ‚îÇ
‚îÇ     (Data Lake)       ‚îÇ    ‚îÇ     MongoDB   (documents)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ     MySQL     (analytics/SQL)   ‚îÇ
                             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                           ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  6. VISUALIZATION                                            ‚îÇ
‚îÇ     Tableau / Power BI ‚Äî dashboards, trend charts, reports   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flow Summary

1. **Data Extraction** ‚Äî Automated scrapers target Moroccan automotive classifieds and extract listing data (price, brand, model, year, mileage, city).
2. **Ingestion** ‚Äî Scraped data is published to Kafka topics, providing a decoupled and fault-tolerant streaming buffer.
3. **Processing** ‚Äî Spark Streaming consumes messages for real-time cleaning and transformation; Spark Batch handles scheduled aggregations.
4. **Storage** ‚Äî Raw data is archived in HDFS. Processed data is written to Cassandra for fast lookups and MySQL for relational queries.
5. **Visualization** ‚Äî Business dashboards and reports are served via Tableau or Power BI.

---

## üìÇ Project Structure

```
‚îú‚îÄ‚îÄ airflow/
‚îÇ   ‚îú‚îÄ‚îÄ dags/                  # Airflow DAG definitions
‚îÇ   ‚îî‚îÄ‚îÄ plugins/               # Custom operators & hooks
‚îú‚îÄ‚îÄ scrapers/
‚îÇ   ‚îú‚îÄ‚îÄ selenium_scraper.py    # Dynamic page scraper
‚îÇ   ‚îî‚îÄ‚îÄ bs4_parser.py          # HTML parsing utilities
‚îú‚îÄ‚îÄ kafka/
‚îÇ   ‚îú‚îÄ‚îÄ producer.py            # Kafka producer config & logic
‚îÇ   ‚îî‚îÄ‚îÄ consumer.py            # Kafka consumer config & logic
‚îú‚îÄ‚îÄ spark/
‚îÇ   ‚îú‚îÄ‚îÄ streaming_job.py       # Spark Streaming processing
‚îÇ   ‚îî‚îÄ‚îÄ batch_job.py           # Spark Batch aggregation jobs
‚îú‚îÄ‚îÄ storage/
‚îÇ   ‚îú‚îÄ‚îÄ cassandra_schema.cql   # Cassandra table definitions
‚îÇ   ‚îú‚îÄ‚îÄ mongo_schema.json      # MongoDB collection schema
‚îÇ   ‚îî‚îÄ‚îÄ mysql_schema.sql       # MySQL table definitions
‚îú‚îÄ‚îÄ docker-compose.yml         # Full containerized environment
‚îî‚îÄ‚îÄ README.md
```

---

## üöÄ Getting Started

### Prerequisites

- Docker & Docker Compose
- Python 3.9+
- Java 11+ (for Spark & Kafka)

### Run the Stack

```bash
# Clone the repository
git clone https://github.com/your-username/moroccan-auto-pipeline.git
cd moroccan-auto-pipeline

# Start all services
docker-compose up -d

# Access Airflow UI
open http://localhost:8080

# Trigger the scraping DAG manually
airflow dags trigger automotive_scraper_dag
```

---

## ‚ú® Key Features

- **Real-Time Processing** ‚Äî Captures market changes as they happen via Kafka + Spark Streaming.
- **Automated Pipelines** ‚Äî Airflow DAGs manage scraping schedules and Spark job execution.
- **Scalable Architecture** ‚Äî Designed to handle high volumes of listings across multiple Moroccan cities.
- **Multi-Layer Storage** ‚Äî Raw archiving (HDFS), fast lookups (Cassandra), and relational analytics (MySQL).
- **ML-Ready Data** ‚Äî Processed data is structured for easy integration with machine learning price prediction models.

---

## üìä Sample Insights

> *"In 2025, the resale value of hybrid vehicles in the Casablanca-Settat region saw a 12% increase compared to diesel counterparts."*

Other example queries the pipeline supports:

- Average resale price of a **Dacia Sandero** by year and city
- Most listed brands in **Marrakech vs Casablanca**
- Price depreciation curve for **diesel vs hybrid** vehicles
- Seasonal listing volume trends across Moroccan regions

---

## üó∫Ô∏è Roadmap

- [ ] Add ML price prediction model (scikit-learn / PySpark MLlib)
- [ ] Expand scraping coverage to additional Moroccan platforms
- [ ] Add real-time alerting for significant price drops
- [ ] Integrate a REST API layer for external data access
- [ ] Add data quality monitoring with Great Expectations

---

## üìÑ License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.
